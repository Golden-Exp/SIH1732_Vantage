{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9421646,"sourceType":"datasetVersion","datasetId":5722494},{"sourceId":9422020,"sourceType":"datasetVersion","datasetId":5722687}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ptflops\n!pip install pytorch_msssim","metadata":{"execution":{"iopub.status.busy":"2024-09-18T14:02:26.350382Z","iopub.execute_input":"2024-09-18T14:02:26.350690Z","iopub.status.idle":"2024-09-18T14:02:55.166148Z","shell.execute_reply.started":"2024-09-18T14:02:26.350656Z","shell.execute_reply":"2024-09-18T14:02:55.165136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ptflops\n  Downloading ptflops-0.7.3-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from ptflops) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->ptflops) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->ptflops) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->ptflops) (1.3.0)\nDownloading ptflops-0.7.3-py3-none-any.whl (18 kB)\nInstalling collected packages: ptflops\nSuccessfully installed ptflops-0.7.3\nCollecting pytorch_msssim\n  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from pytorch_msssim) (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->pytorch_msssim) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->pytorch_msssim) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->pytorch_msssim) (1.3.0)\nDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\nInstalling collected packages: pytorch_msssim\nSuccessfully installed pytorch_msssim-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torchvision.transforms import transforms\nfrom PIL import Image\nclass CustomDataset(Dataset):\n    def __init__(self, files, transform=None):\n        self.transform = transform\n        self.files = files\n    def __len__(self):\n        return len(self.files)\n    def __getitem__(self, idx):\n        in_image = Image.open(\"/kaggle/input/files-for-training/Dataset/SIH_24/Noisy Images/\"+self.files[idx])\n        transform = transforms.Compose([\n            transforms.Resize((256, 256)),\n            transforms.ToTensor()])\n        out_image = Image.open(\"/kaggle/input/files-for-training/Dataset/SIH_24/Ground Truth/\"+self.files[idx]).convert('L')\n        return transform(in_image), transform(out_image)","metadata":{"execution":{"iopub.status.busy":"2024-09-18T14:02:55.168351Z","iopub.execute_input":"2024-09-18T14:02:55.168694Z","iopub.status.idle":"2024-09-18T14:03:00.236376Z","shell.execute_reply.started":"2024-09-18T14:02:55.168655Z","shell.execute_reply":"2024-09-18T14:03:00.235513Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(1, \"/kaggle/input/rdunet\")\nimport yaml\nimport torch\nimport torch.optim as optim\nfrom os.path import join\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import transforms\nfrom ptflops import get_model_complexity_info\n\nfrom model import RDUNet\nfrom data_management import NoisyImagesDataset, DataSampler\nfrom train import fit_model\nfrom transforms import AdditiveWhiteGaussianNoise, RandomHorizontalFlip, RandomVerticalFlip, RandomRot90\nfrom utils import set_seed\n\n\ndef main():\n    with open('/kaggle/input/rdunet/config.yaml', 'r') as stream:            # Load YAML configuration file.\n        config = yaml.safe_load(stream)\n\n    model_params = config['model']\n    model_params[\"channels\"] = 1\n    train_params = config['train']\n    val_params = config['val']\n\n    # Defining model:\n    set_seed(0)\n    model = RDUNet(**model_params)\n\n    print('Model summary:')\n    test_shape = (model_params['channels'], train_params['patch size'], train_params['patch size'])\n    with torch.no_grad():\n        macs, params = get_model_complexity_info(model, test_shape, as_strings=True,\n                                                 print_per_layer_stat=False, verbose=False)\n        print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n        print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n\n    # Define the model name and use multi-GPU if it is allowed.\n    model_name = 'model_color' if model_params['channels'] == 3 else 'model_gray'\n    device = torch.device(train_params['device'])\n    print(\"Using device: {}\".format(device))\n    if torch.cuda.device_count() > 1 and 'cuda' in device.type and train_params['multi gpu']:\n        model = nn.DataParallel(model)\n        print('Using multiple GPUs')\n\n    model = model.to(device)\n    param_group = []\n    for name, param in model.named_parameters():\n        if 'conv' in name and 'weight' in name:\n            p = {'params': param, 'weight_decay': train_params['weight decay']}\n        else:\n            p = {'params': param, 'weight_decay': 0.}\n        param_group.append(p)\n\n    # Load training and validation file names.\n    # Modify .txt files if datasets do not fit in memory.\n    with open('/kaggle/input/files-for-training/train_files.txt', 'r') as f_train, open('/kaggle/input/files-for-training/valid_files.txt', 'r') as f_val:\n        raw_train_files = f_train.read().splitlines()\n        raw_val_files = f_val.read().splitlines()\n        #train_files = list(map(lambda file: join(\"/kaggle/input/files-for-training/Dataset/SIH_24/Noisy Images\", file), raw_train_files))\n        #val_files = list(map(lambda file: join(\"/kaggle/input/files-for-training/Dataset/SIH_24/Noisy Images\", file), raw_val_files))\n\n    training_transforms = transforms.Compose([\n        RandomHorizontalFlip(),\n        RandomVerticalFlip(),\n        RandomRot90()\n    ])\n\n    # Predefined noise level\n    #train_noise_transform = [AdditiveWhiteGaussianNoise(train_params['noise level'], clip=True)]\n    #val_noise_transforms = [AdditiveWhiteGaussianNoise(s, fix_sigma=True, clip=True) for s in val_params['noise levels']]\n    \n    transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor()])\n    print('\\nLoading training dataset:')\n    training_dataset = CustomDataset(raw_train_files, transform)\n\n    print('\\nLoading validation dataset:')\n    validation_dataset = CustomDataset(raw_val_files)\n    \n    # Training in sub-epochs:\n    print('Training patches:', len(training_dataset))\n    print('Validation patches:', len(validation_dataset))\n    n_samples = len(training_dataset) // train_params['dataset splits']\n    n_epochs = 10\n    sampler = DataSampler(training_dataset, num_samples=n_samples)\n\n    data_loaders = {\n        'train': DataLoader(training_dataset, 1, num_workers=train_params['workers']),\n        'val': DataLoader(validation_dataset, 1, num_workers=val_params['workers']),\n    }\n\n    # Optimization:\n    learning_rate = train_params['learning rate']\n    step_size = train_params['scheduler step'] * train_params['dataset splits']\n\n    criterion = nn.L1Loss()\n    optimizer = optim.AdamW(param_group, lr=learning_rate)\n    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=train_params['scheduler gamma'])\n\n    # Train the model\n    fit_model(model, data_loaders, model_params['channels'], criterion, optimizer, lr_scheduler, device,\n              n_epochs, val_params['frequency'], train_params['checkpoint path'], model_name)\n    return model\nmodel = main()","metadata":{"execution":{"iopub.status.busy":"2024-09-18T14:03:00.237985Z","iopub.execute_input":"2024-09-18T14:03:00.238447Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Model summary:\nComputational complexity:       50.48 GMac\nNumber of parameters:           166.37 M\nUsing device: cuda:0\n\nLoading training dataset:\n\nLoading validation dataset:\nTraining patches: 149\nValidation patches: 50\n\nEpoch: 1/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\nTraining - Loss:4.43289e-02 - PSNR:25.34943 - SSIM:0.45558: 100%|███████████| 149/149 [02:01<00:00,  1.23it/s]\nValidation - Loss:3.34984e-02 - PSNR:27.46965 - SSIM:0.56904: 100%|███████████| 50/50 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"Training - Loss:2.22081e-01 - PSNR:25.98713 - SSIM:0.53900: 100%|███████████| 149/149 [02:05<00:00,  1.19it/s]\nValidation - Loss:1.45881e+02 - PSNR:-45.63456 - SSIM:0.00000: 100%|██████████| 50/50 [00:14<00:00,  3.43it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:3.70707e+02 - PSNR:-4.51263 - SSIM:0.10075: 100%|███████████| 149/149 [02:04<00:00,  1.19it/s]\nValidation - Loss:5.95187e-02 - PSNR:22.81799 - SSIM:0.38288: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 4/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:5.15166e-02 - PSNR:24.07380 - SSIM:0.40602: 100%|███████████| 149/149 [02:05<00:00,  1.19it/s]\nValidation - Loss:4.74428e-02 - PSNR:24.74899 - SSIM:0.44171: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 5/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:4.34623e-02 - PSNR:25.42557 - SSIM:0.45911: 100%|███████████| 149/149 [02:04<00:00,  1.19it/s]\nValidation - Loss:4.23521e-02 - PSNR:25.62228 - SSIM:0.47693: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 6/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:4.02114e-02 - PSNR:25.97375 - SSIM:0.47977: 100%|███████████| 149/149 [02:05<00:00,  1.19it/s]\nValidation - Loss:3.96780e-02 - PSNR:26.07348 - SSIM:0.49684: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 7/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:3.90195e-02 - PSNR:26.17974 - SSIM:0.49139: 100%|███████████| 149/149 [02:05<00:00,  1.19it/s]\nValidation - Loss:3.80439e-02 - PSNR:26.35769 - SSIM:0.51057: 100%|███████████| 50/50 [00:14<00:00,  3.45it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 8/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:3.81399e-02 - PSNR:26.33822 - SSIM:0.49924: 100%|███████████| 149/149 [02:04<00:00,  1.19it/s]\nValidation - Loss:3.74628e-02 - PSNR:26.45665 - SSIM:0.51506: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 9/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:3.73939e-02 - PSNR:26.48174 - SSIM:0.50606: 100%|███████████| 149/149 [02:05<00:00,  1.19it/s]\nValidation - Loss:3.65013e-02 - PSNR:26.63057 - SSIM:0.52578: 100%|███████████| 50/50 [00:14<00:00,  3.44it/s]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 10/10 - Learning rate: 1.0000e-04\n","output_type":"stream"},{"name":"stderr","text":"\nTraining - Loss:3.62483e-02 - PSNR:26.73592 - SSIM:0.51206:  44%|█████▎      | 66/149 [00:55<01:09,  1.19it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:18:40.130760Z","iopub.execute_input":"2024-09-17T19:18:40.131179Z","iopub.status.idle":"2024-09-17T19:18:40.138023Z","shell.execute_reply.started":"2024-09-17T19:18:40.131141Z","shell.execute_reply":"2024-09-17T19:18:40.136960Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:19:41.371121Z","iopub.execute_input":"2024-09-17T19:19:41.371660Z","iopub.status.idle":"2024-09-17T19:20:17.870264Z","shell.execute_reply.started":"2024-09-17T19:19:41.371605Z","shell.execute_reply":"2024-09-17T19:20:17.869290Z"},"trusted":true},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"/kaggle/working/model.zip","text/html":"<a href='model.zip' target='_blank'>model.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:05:27.015425Z","iopub.execute_input":"2024-09-17T19:05:27.015896Z","iopub.status.idle":"2024-09-17T19:05:27.062285Z","shell.execute_reply.started":"2024-09-17T19:05:27.015848Z","shell.execute_reply":"2024-09-17T19:05:27.060848Z"},"trusted":true},"execution_count":60,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}